### Input
# input rgba image path (default to None, can be load in GUI too)
input: data/jaeho_00000_rgba.png
# input text prompt (default to None, can be input in GUI too)
prompt: portrait of a 20-year-old woman, long black hair, black turtleneck, silver necklace, white background, upper body, calm expression.
negative_prompt:
# input mesh for stage 2 (auto-search from stage 1 output path if None)
mesh:
# estimated elevation angle for input image 
elevation: 0
ref_size: 256
# density thresh for mesh extraction
density_thresh: 1

### CameraCtrl Params
cameractrl_model_path: checkpoints/stable-video-diffusion-img2vid-xt
cameractrl_model_config_path: configs/svdxt_320_576_cameractrl.yaml
cameractrl_trajectory_file: data/cameractrl_assets/pose_files/colmap_jaeho_svdxt.txt
cameractrl_pose_adaptor_ckpt: checkpoints/CameraCtrl_svdxt.ckpt
cameractrl_enable_xformers: True
cameractrl_target_distance: 2.0  # Target distance for pose normalization
cameractrl_image_height: 320
cameractrl_image_width: 576
cameractrl_num_frames: 25
cameractrl_num_inference_steps: 25
cameractrl_min_guidance_scale: 1.0
cameractrl_max_guidance_scale: 3.0
cameractrl_original_pose_width: 720
cameractrl_original_pose_height: 1280

### Output
outdir: logs
mesh_format: obj
save_path: ???

### Training
# use mvdream instead of sd 2.1
mvdream: False
# use imagedream
imagedream: False
# use stable-zero123 instead of zero123-xl
stable_zero123: False
# use camera control
camera_control: True
# guidance loss weights (0 to disable)
lambda_sd: 0
lambda_zero123: 1
lambda_cameractrl: 1
lambda_render: 1
# warmup rgb supervision for image-to-3d
warmup_rgb_loss: False
# training batch size per iter
batch_size: 1
# training iterations for stage 1
iters: 500
# whether to linearly anneal timestep
anneal_timestep: True
# training iterations for stage 2
iters_refine: 50
# training camera radius
radius: 2
# training camera fovy
fovy: 49.1 # align with zero123 rendering setting (ref: https://github.com/cvlab-columbia/zero123/blob/main/objaverse-rendering/scripts/blender_script.py#L61
# training camera min elevation
min_ver: -30
# training camera max elevation
max_ver: 30
# checkpoint to load for stage 1 (should be a ply file)
load:
# whether allow geom training in stage 2
train_geo: False
# prob to invert background color during training (0 = always black, 1 = always white)
invert_bg_prob: 0.5


### GUI
gui: False
force_cuda_rast: False
# GUI resolution
H: 800
W: 800

### Gaussian splatting
num_pts: 5000
sh_degree: 0
position_lr_init: 0.001
position_lr_final: 0.00002
position_lr_delay_mult: 0.02
position_lr_max_steps: 500
feature_lr: 0.01
opacity_lr: 0.05
scaling_lr: 0.005
rotation_lr: 0.005
percent_dense: 0.01
density_start_iter: 100
density_end_iter: 3000
densification_interval: 100
opacity_reset_interval: 700
densify_grad_threshold: 0.01

### Textured Mesh
geom_lr: 0.0001
texture_lr: 0.2